---
title: "PS270 Final Project"
author: "Natalie Thuente"
description: "My final project"
output:
  distill::distill_article:
    self_contained: false
---

# Introduction 

Research Question: Is one political party more likely to post inaccurate or misleading data on social media than the other? This research is studying the relationship between political partisanship (Republican or Democrat) and accuracy of social media posts, this is to determine if there is a causal relationship between an individual's political affiliation and likelihood to spread inaccurate information. The data supporting this research has been obtained from: "https://www.kaggle.com/datasets/mrisdal/fact-checking-facebook-politics-pages/data".

My hypothesis is that the Republican party is more likely to curate false social media content. My behavioral explanation of this is rooted in recent political events and the overall tone of hostility since the 2020 election. The Republican party has been outspokenly discontent with the results of the 2020 election, contesting the validity of the election, ultimately culminating in the January 6th insurrection. These feelings of hostility have been expressed through many social media posts, and I believe that these extreme views and an abundance of emotional content could explain a lack of accuracy in Republican social media posts.


```{r}
library(tidyverse)
facebook <- read_csv("facebook-fact-check.csv")
facebook
```

# Data: describe data source, key dependent and independent variables, how they are measured, plot summarizing dependent variable


My research was a cross-sectional design with data from: "https://www.kaggle.com/datasets/mrisdal/fact-checking-facebook-politics-pages/data". The explanatory variable of interest is the partisan affiliation of the social media post, which was determined by the partisan identity of the account creating the post. The response variable was the accuracy of post. This was measured by raters at Buzzfeed. Each rater was given a rotating selection of accounts from different parties on each day, with each rater being given the same criteria for how to review posts.

Truth Categories:

(4) Mostly True: The post and any related link or image are based on factual information and portray it accurately. This lets them interpret the event/info in their own way, so long as they do not misrepresent events, numbers, quotes, reactions, etc., or make information up. This rating does not allow for unsupported speculation or claims.

(3) Mixture of True and False: Some elements of the information are factually accurate, but some elements or claims are not. This rating should be used when speculation or unfounded claims are mixed with real events, numbers, quotes, etc., or when the headline of the link being shared makes a false claim but the text of the story is largely accurate. It should also only be used when the unsupported or false information is roughly equal to the accurate information in the post or link. Finally, use this rating for news articles that are based on unconfirmed information.

(2) Mostly False: Most or all of the information in the post or in the link being shared is inaccurate. This should also be used when the central claim being made is false.

(1) No Factual Content: This rating is used for posts that are pure opinion, comics, satire, or any other posts that do not make a factual claim. This is also the category to use for posts that are of the “Like this if you think…” variety.


To disprove my hypothesis, the percentage of inaccurate posts created by Democratic accounts would have to be greater than that of Republican accounts


This bar plot shows the relationship between Party and accuracy of social media posts. For each accuracy category (4 being the most accurate, 1 being the least), the plot displays the percentage of total posts that fall under this category for each party.


Count the percentage of total posts that fall under each accuracy classification for each party.

```{r}
parties <- facebook |>
  filter(Category != "mainstream") |>
  mutate(Party = if_else(Category == "left", "Democrat", "Republican"),
         accuracy_rating = case_when(
           Rating == "mostly true" ~ 4,
           Rating == "mixture of true and false" ~ 3,
           Rating == "mostly false" ~ 2,
           Rating == "no factual content" ~ 1))
party_accuracy <- parties |>
  group_by(Party, accuracy_rating)  |>
  summarize(n = n()) |> 
  mutate(p = n / sum(n))
  # mutate(n = if_else(Party == "Democrat", n/471, n/666))
party_accuracy
```


Now that the data is organized by party and accuracy rating, this is a bar graph comparing the results.

```{r}
accuracy_plot <- party_accuracy |>
  ggplot(aes(x = accuracy_rating, y = n)) +
  geom_bar(stat = "identity", aes(fill = Party), position = position_dodge()) +
  scale_fill_manual(values = c("Democrat" = "steelblue1", "Republican" = "indianred1")) +
  labs(title = "Percentage Social Media Post Accuracy per Party", 
  x = "Accuracy Rating", 
  y = "Proportion of total posts", 
  caption = "4: Mostly True
       3: Mixture of True and False
       2: Mostly False
       1: No Factual Content") +
  theme_minimal()
accuracy_plot
```


# Results: scatterplot, barplot or boxplot with regression and paragraph summarizing results

To better visualize the results, I have added a linear regression of the data by creating a binary variable to represent Party. Because I have set the Democrat value to '1' and the Republican value to '0', a positive value would indicate higher average ratings for the Republican Party, and a negative value would indicate the opposite, higher average ratings for the Democratic Party.


Table summarizing the Average Accuracy Rating for each Party.

```{r}
analysis <- parties |>
  group_by(Party) |>
    summarize("Average Accuracy Rating" = mean(accuracy_rating))
knitr::kable(analysis)
```


Linear Regression analyzing the relationship between Partisan Affiliation and Accuracy of social media posts, holding all other variables constant.

```{r}
parties <- parties |>
  mutate(PartyBinary = if_else(Party == "Republican", 1, 0))
model <- lm(accuracy_rating ~ Party, data = parties)
summary(model)
```
The results of the linear regression, specifically the Intercept, indicate the average accuracy rating for the Democratic party is 3.023, as the Democratic party was assigned the value '0'. The PartyBinary coefficient of 0.04421 indicates posts from the Republican party had a higher Average Social Media Accuracy Ranking than posts from the Democratic party.

Observing the resulting p-value of 0.5275, in the context of $\alpha$ value of 0.05, we are unable to reject the null hypothesis and determine a causal relationship between Party Affiliation and Social Media post Accuracy, finding the Party Affiliation to be not statistically significant in predicting Social Media post Accuracy.

```{r}
box_plot <- parties |>
  ggplot(aes(x = Party, y = accuracy_rating)) +
  geom_boxplot(aes(fill = Party)) +
  scale_fill_manual(values = c("Democrat" = "steelblue1", "Republican" = "indianred1")) +
  labs(title = "Distribution of Accuracy Ratings by Party", x = "Political Party", y = "Accuracy Rating") +
  theme_minimal()
box_plot
```



# Conclusion

To answer my research question, I was incorrect and my hypothesis proven wrong.

